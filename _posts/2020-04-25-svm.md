---
layout: post
title: "SVM "
date: 2020-04-25T15:19:43.401Z
updated_date: 2020-04-25T15:19:43.417Z
published: false
tags:
  - machinelearning
  - datascience
  - python
  - sklearn
categories:
  - machinelearning
  - datascience
  - python
  - sklearn
show_ads: false
include_mathjax: true
---
SVM or support vector machines are supervised learning models that analyze data and recognize patterns on its own. They are used for both classification and regression analysis.

SVM model is the representation of the dataset as points in space, so that the example of the separate categories are divided by a clear gap which is as wide as possible.

Any new incoming data is then mapped to one of these few categories based on which side of the gap they fall on.

{% include lazyload.html image_src="https://i.ibb.co/XYgV0Yg/Screenshot-2020-04-25-at-9-02-13-PM.png" image_alt="Two dimensional SVM example" image_title="Two dimensional SVM example" %}

For example, in the above image we can clearly see that there are two categories in the dataset. Category blue and category pink.

Our aim to differentiate between the two categories. One simple way of doing that is to draw a line in between the two categories. But as we can see, there are a lot of lines which can clearly divide dataset into two parts.

What we actually do is that we choose a hyperplane that maximizes the margin between the classes. The data points (Vectors) touching the two outer lines are called support vectors.

This simple example of two dimension linear plots can be further used in a dataset having further more dimensions. Each time our idea will be to draw a hyperplane which can divide the data into different categories.

Now we are going to talk about some related mathematics and discuss different terms related to SVM.

In general the discussion of SVM is divided into three parts according to how SVM evolved.

* Maximal Margin Classifier
* Support Vector Classifier
* Support Vector Machine

We will slowly move the article toward the Support Vector Machine but for proper understanding of SVM's we have to go through, Maximal Margin Classifier and Support Vector Classifier.

## Maximal Margin Classifier

Maximal Margin Classifier is a model which is used to classify the observations into two parts using a hyperplane.

### What is a Hyperplane?

Simply put a hyperplane is a subspace in p-dimensional space having `p -1` dimensions. For example, in two-dimensional space the hyperplane will be of 1 dimension, or it will be a line. Similarly, in case of 3 dimensions it will be a two-dimensional plane.

In two dimensions the equation of the hyperplane are given by,

{% include math.html math_code="$\beta_0 + \beta_0X_1 + \beta_0X_2 = 0$" style="margin-top:0.2em;" %}

{% include math.html math_code="$where\ vector\ (X1,\ X2)\ is\ on\ the\ hyperplane$" %}

We can also find some similarity of this equation with the equation of line.

Its fairly easy to extend this equation and find the equation of a hyperplane in `p` dimensions.

